{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subsequent-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twarc import Twarc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea076f0e-8d61-4ebd-9320-4d5ae8df9d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b911b12-1668-43ea-b9d7-77c7579d8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../bearer_token.yaml') as f:\n",
    "    bearer_token = yaml.safe_load(f)['bearer_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb9e0c9-ee4c-4b5b-904b-b480744fa27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2f002a3-9753-453d-b7a5-37daf9131959",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('../test_data/twacapic-parliamentarians-tryout-2.csv', lineterminator='\\n', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ac9925a-f321-4b9c-8ef6-080a1dd4f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = tweets['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e33a7666-37b9-421b-bb9b-51f1e680acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = ids #.sample(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "express-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Twarc2(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11bc6c1b-79db-40b4-bc3f-94941ba3b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b9552-8c3d-4023-83d2-b499d284127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "from math import ceil\n",
    "\n",
    "lookup = t.tweet_lookup(test_ids.values)\n",
    "\n",
    "errors = list()\n",
    "\n",
    "pages = 0\n",
    "\n",
    "for page in lookup:\n",
    "    pages += 1\n",
    "    \n",
    "    for tweet in page['data']:\n",
    "        if 'withheld' in tweet.keys(): # check whether tweet is withheld in any country\n",
    "            errors.append(tweet) # if so, append tweet object to errors\n",
    "    \n",
    "    page_length = len(page['data'])\n",
    "\n",
    "    if page_length != 100: # Now focus on 'incomplete' pages\n",
    "\n",
    "        if len(test_ids) >= pages * 100: # There should be errors if page is not last page\n",
    "            assert 'errors' in page.keys()\n",
    "\n",
    "        n = 0\n",
    "        \n",
    "        if 'errors' in page.keys():\n",
    "            for error in page['errors']:\n",
    "                if error['parameter'] == 'ids' and error['resource_type'] == 'tweet': \n",
    "                # These fields seem to mark a 'deleted' or 'protected' tweet error\n",
    "                \n",
    "                    assert error['value'] in test_ids.values # just to be sure that our logic is sound\n",
    "                    \n",
    "                    errors.append(error)\n",
    "                    \n",
    "                    n += 1\n",
    "        \n",
    "        if len(test_ids) >= pages * 100:     # If page is not last page\n",
    "            assert page_length == 100 - n    # the number of errors should explain the missing tweets.\n",
    "\n",
    "    stdout.write(f'\\r{pages}')\n",
    "    stdout.flush()\n",
    "\n",
    "assert pages == ceil(len(test_ids) / 100)    # Have we processed all pages?\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da1f4a4a-95b5-42ae-9b35-0635df7f74f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndjson\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ccf17e74-f3e7-40a0-8aca-2ea90bd2af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{datetime.strftime(datetime.now(), \"%Y%m%d\")}_deleted_tweets.ndjson', 'w') as f:  # write to file with today's date in front\n",
    "    ndjson.dump(errors, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
